{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import f1_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "from Scripts import VoxNet\n",
    "from Scripts import VoxelizeData as vd\n",
    "\n",
    "# Use GPU if available, has issues with these small batch sizes\n",
    "if torch.cuda.is_available(): \n",
    "    dev = torch.device(\"cuda\")\n",
    "else: \n",
    "    dev = torch.device(\"cpu\")\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "#dev = torch.device(\"cpu\")\n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 1 of the following 3 cells depending on which dataset you want to use\n",
    "#### Load ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = np.load('Data/ModelNet40/ModelNet40Train.npz', allow_pickle=True)\n",
    "\n",
    "train_data = data['data']\n",
    "train_labels = data['labels']\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# Load test data\n",
    "data = np.load('Data/ModelNet40/ModelNet40Test.npz', allow_pickle=True)\n",
    "\n",
    "test_data = data['data']\n",
    "test_labels = data['labels']\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "output_file = 'Data/ModelNet40/voxnet_results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ShapeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = np.load('Data/ShapeNet/ShapeNetTrain.npz', allow_pickle=True)\n",
    "\n",
    "train_data = data['data']\n",
    "train_labels = data['labels']\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# Load test data\n",
    "data = np.load('Data/ShapeNet/ShapeNetTest.npz', allow_pickle=True)\n",
    "\n",
    "test_data = data['data']\n",
    "test_labels = data['labels']\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "output_file = 'Data/ShapeNet/voxnet_results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Toys4K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "data = np.load('Data/toys4k/toys4kTrain.npz', allow_pickle=True)\n",
    "\n",
    "train_data = data['data']\n",
    "train_labels = data['labels']\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# Load test data\n",
    "data = np.load('Data/toys4k/toys4kTest.npz', allow_pickle=True)\n",
    "\n",
    "test_data = data['data']\n",
    "test_labels = data['labels']\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "output_file = 'Data/toys4k/voxnet_results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VoxNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_voxnet(model, optimizer, criterion, train_loader, batch_size, decay_iter, learning_rate, dev):\n",
    "    # Train VoxNet\n",
    "    for (vox_grids, vox_labels) in train_loader:\n",
    "        vox_grids = vox_grids.to(dev)\n",
    "        vox_labels = vox_labels.to(dev)\n",
    "\n",
    "        batch_number += 1\n",
    "\n",
    "        if batch_number % decay_iter == 0:\n",
    "            print(\"Decreasing learning rate\")\n",
    "            learning_rate *= 0.1\n",
    "\n",
    "        # print(len(vox_grids))\n",
    "        if (len(vox_grids) < batch_size):\n",
    "            continue\n",
    "\n",
    "        output = model(vox_grids)\n",
    "        loss = criterion(output, vox_labels)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_voxnet(model, optimizer, batch_size, num_classes, dataloader):\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    predictions_train = []\n",
    "    labels_train = []\n",
    "\n",
    "    # Test the model on the training data\n",
    "    for (grids, labels) in dataloader:\n",
    "        if (len(grids) < batch_size):\n",
    "            continue\n",
    "\n",
    "        grids = grids.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "\n",
    "        output = model(grids)\n",
    "\n",
    "        _, predictions = torch.max(output, 1)\n",
    "\n",
    "        # Determine the number of correct predictions\n",
    "        num_correct += (predictions.cpu() == labels.cpu()).sum().item()\n",
    "                \n",
    "        # Determine the number of total predictions made\n",
    "        total += labels.shape[0]\n",
    "                \n",
    "        # Store the predictions and labels for calculating the metrics\n",
    "        predictions_train += predictions.cpu().tolist()\n",
    "        labels_train += labels.cpu().tolist()\n",
    "            \n",
    "    # Calculate the metrics\n",
    "    accuracy = (num_correct / total) * 100.0\n",
    "    f1 = f1_score(labels_train, predictions_train, average='weighted')\n",
    "    mse = mean_squared_error(labels_train, predictions_train)\n",
    "    conf_matrix = confusion_matrix(labels_train, predictions_train, labels=[i for i in range(num_classes)])\n",
    "\n",
    "    return accuracy, f1, mse, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Parameters Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# classes = np.unique(train_labels)\n",
    "# num_classes = len(classes)\n",
    "# print(num_classes)\n",
    "\n",
    "# # Make a parameter grid for grid search\n",
    "# param_grid = {'epochs': [10, 20, 30, 40, 50],\n",
    "#         'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "#         'momentum': [0.9, 0.95, 0.99, 0.999],\n",
    "#         'weight_decay': [0.01, 0.001, 0.0001, 0.00001],\n",
    "#         'decay_iter': [10000, 20000, 40000, 80000]\n",
    "#         }\n",
    "\n",
    "# # Store index of the best iteration for each metric\n",
    "# best_results = {'f1': 0, 'acc': 0, 'mse': 0}\n",
    "\n",
    "# # Store the f1 score, accuracy, MSEs, and confusion matrices for each parameter combination, as well as the parameters\n",
    "# metrics = {'f1_scores': [], 'accuracies': [], 'mses': [], 'conf_matrices': []}\n",
    "# results = {'train': [], 'test': [], 'params': [], 'best': best_results}\n",
    "\n",
    "# # Load data in batch sizes\n",
    "# train_loader = vd.build_dataloader(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = vd.build_dataloader(test_data, test_labels, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# best_acc = 0\n",
    "# best_f1 = 0\n",
    "# best_mse = float('inf')\n",
    "\n",
    "# # Apply grid search using the sklearn ParameterGrid\n",
    "# for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "#     print(f'iteration {i}: {params}')\n",
    "\n",
    "#     # Get the parameters\n",
    "#     learning_rate = params['learning_rate']\n",
    "#     momentum = params['momentum']\n",
    "#     weight_decay = params['weight_decay']\n",
    "#     decay_iter = params['decay_iter']\n",
    "#     epochs = params['epochs']\n",
    "\n",
    "#     # Store the metrics for this iteration so we can plot them later\n",
    "#     results['test'].append(metrics.copy())\n",
    "#     results['train'].append(metrics.copy())\n",
    "\n",
    "#     # Store the parameters for this iteration\n",
    "#     results['params'].append(params)\n",
    "\n",
    "#     # Initialize the model\n",
    "#     model = VoxNet.VoxNet(num_classes)\n",
    "#     model = model.float()\n",
    "#     model.to(dev)\n",
    "\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     batch_number = 0\n",
    "\n",
    "#     # Train and test the model for the specified number of epochs\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         train_voxnet(model, optimizer, criterion, train_loader, batch_size, decay_iter, learning_rate, dev)\n",
    "\n",
    "#         # Test VoxNet after training\n",
    "#         with torch.no_grad():\n",
    "            \n",
    "#             # Test the model on the training data\n",
    "#             accuracy, f1, mse, conf_matrix = test_voxnet(model, optimizer, batch_size, num_classes, train_loader)\n",
    "\n",
    "#             # Store the training results\n",
    "#             results['train'][i]['accuracies'].append(accuracy)\n",
    "#             results['train'][i]['f1_scores'].append(f1)\n",
    "#             results['train'][i]['mses'].append(mse)\n",
    "#             results['train'][i]['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "#             # Print final results of the model before moving on to the next parameter combination\n",
    "#             if epoch == epochs-1:\n",
    "#                 print(\"Final Training Accuracy:\", accuracy)\n",
    "#                 print(\"Final Training F1 Score:\", f1)\n",
    "#                 print(\"Final Training MSE:\", mse)\n",
    "\n",
    "#             # Test the model on the test data\n",
    "#             accuracy, f1, mse, conf_matrix = test_voxnet(model, optimizer, batch_size, num_classes, test_loader)\n",
    "\n",
    "#             # Store the results\n",
    "#             results['test'][i]['accuracies'].append(accuracy)\n",
    "#             results['test'][i]['f1_scores'].append(f1)\n",
    "#             results['test'][i]['mses'].append(mse)\n",
    "#             results['test'][i]['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "#             # Print final results of the model before moving on to the next parameter combination\n",
    "#             if epoch == epochs-1:\n",
    "#                 print(\"Final Testing Accuracy:\", accuracy)\n",
    "#                 print(\"Final Testing F1 Score:\", f1)\n",
    "#                 print(\"Final Testing MSE:\", mse)\n",
    "\n",
    "#             # Take note of the model with the best accuracy on the test set once all epochs are complete\n",
    "#             if accuracy > best_acc and epoch == epochs-1:\n",
    "#                 results['best']['acc'] = i\n",
    "            \n",
    "#             # Take note of the model with the best f1 score on the test set once all epochs are complete\n",
    "#             if f1 > best_f1 and epoch == epochs-1:\n",
    "#                 results['best']['f1'] = i\n",
    "\n",
    "#             # Take note of the model with the best MSE on the test set once all epochs are complete\n",
    "#             if mse < best_mse and epoch == epochs-1:\n",
    "#                 results['best']['mse'] = i\n",
    "\n",
    "\n",
    "# # line_one = plt.plot(range(len(training_accuracy)), training_accuracy, label='Training Accuracy')\n",
    "# # line_two = plt.plot(range(len(testing_accuracy)), testing_accuracy, label='Testing Accuracy')\n",
    "# # plt.legend()\n",
    "# # plt.ylim(0,100.0)\n",
    "# # plt.ylabel('Accuracy')\n",
    "# # plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Best Model\n",
    "The best hyperparameters we found for VoxNet are:\n",
    "\n",
    "- epochs = 50\n",
    "- learning rate = 0.001\n",
    "- weight decay = 0.001\n",
    "- momentum = 0.9\n",
    "- decay_iter = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "classes = np.unique(train_labels)\n",
    "num_classes = len(classes)\n",
    "print(num_classes)\n",
    "\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.001\n",
    "decay_iter = 20000\n",
    "\n",
    "# Store the f1 score, accuracy, MSEs, and confusion matrices for each parameter combination, as well as the parameters\n",
    "results = {'f1_scores': [], 'accuracies': [], 'mses': [], 'conf_matrices': []}\n",
    "\n",
    "# Load data in batch sizes\n",
    "train_loader = vd.build_dataloader(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "test_loader = vd.build_dataloader(test_data, test_labels, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = VoxNet.VoxNet(num_classes)\n",
    "model = model.float()\n",
    "model.to(dev)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "batch_number = 0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Train VoxNet\n",
    "    train_voxnet(model, optimizer, criterion, train_loader, batch_size, decay_iter, learning_rate, dev)\n",
    "\n",
    "    # Test VoxNet after training\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Test the model on the training data\n",
    "        accuracy, f1, mse, conf_matrix = test_voxnet(model, optimizer, batch_size, num_classes, train_loader)\n",
    "\n",
    "        # Store the training results\n",
    "        results['accuracies'].append(accuracy)\n",
    "        results['f1_scores'].append(f1)\n",
    "        results['mses'].append(mse)\n",
    "        results['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "        # Test the model on the test data\n",
    "        accuracy, f1, mse, conf_matrix = test_voxnet(model, optimizer, batch_size, num_classes, test_loader)\n",
    "\n",
    "        # Store the results\n",
    "        results['accuracies'].append(accuracy)\n",
    "\n",
    "        print (f\"Epoch: {epoch + 1}\")\n",
    "        print (f\"Training Accuracy: {accuracy}\")\n",
    "        print (f\"Training F1 Score: {f1}\")\n",
    "        print (f\"Training MSE: {mse}\")\n",
    "\n",
    "        print (f\"\\nTesting Accuracy: {accuracy}\")\n",
    "        print (f\"Testing F1 Score: {f1}\")\n",
    "        print (f\"Testing MSE: {mse}\")\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(len(results['accuracies'])), results['accuracies'], label='Accuracy')\n",
    "plt.plot(range(len(results['f1_scores'])), results['f1_scores'], label='F1 Score')\n",
    "plt.plot(range(len(results['mses'])), results['mses'], label='MSE')\n",
    "plt.legend()\n",
    "plt.ylim(0,100.0)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
