{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import f1_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay\n",
    "from Scripts import CNN\n",
    "from Scripts import VoxelizeData as vd\n",
    "\n",
    "# Use GPU if available, has issues with these small batch sizes\n",
    "if torch.cuda.is_available(): \n",
    "    dev = torch.device(\"cuda\")\n",
    "else: \n",
    "    dev = torch.device(\"cpu\")\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "#dev = torch.device(\"cpu\")\n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset To Train Model\n",
    "\n",
    "Change **training_set** to any of the following:\n",
    "\n",
    "- ModelNet40\n",
    "- ShapeNet\n",
    "- Toys4k\n",
    "\n",
    "If you have 16GB of RAM or less, I recommend using the Toys dataset, and then avoiding the cross-dataset evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = \"ModelNet40\"\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = vd.load_dataset(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(model, optimizer, criterion, train_loader, batch_size, decay_iter, learning_rate, batch_number, dev):\n",
    "    # Train cnn\n",
    "    for (vox_grids, vox_labels) in train_loader:\n",
    "        vox_grids = vox_grids.to(dev)\n",
    "        vox_labels = vox_labels.to(dev)\n",
    "\n",
    "        batch_number += 1\n",
    "\n",
    "        if batch_number % decay_iter == 0:\n",
    "            print(\"Decreasing learning rate\")\n",
    "            learning_rate *= 0.1\n",
    "\n",
    "        if (len(vox_grids) < batch_size):\n",
    "            continue\n",
    "\n",
    "        output = model(vox_grids)\n",
    "        loss = criterion(output, vox_labels)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_number, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(model, batch_size, num_classes, dataloader):\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    predictions_test = []\n",
    "    labels_test = []\n",
    "\n",
    "    # Test the model on the training data\n",
    "    for (grids, labels) in dataloader:\n",
    "        if (len(grids) < batch_size):\n",
    "            continue\n",
    "\n",
    "        grids = grids.to(dev)\n",
    "        labels = labels.to(dev)\n",
    "\n",
    "        output = model(grids)\n",
    "\n",
    "        _, predictions = torch.max(output, 1)\n",
    "\n",
    "        # Determine the number of correct predictions\n",
    "        num_correct += (predictions.cpu() == labels.cpu()).sum().item()\n",
    "                \n",
    "        # Determine the number of total predictions made\n",
    "        total += labels.shape[0]\n",
    "                \n",
    "        # Store the predictions and labels for calculating the metrics\n",
    "        predictions_test += predictions.cpu().tolist()\n",
    "        labels_test += labels.cpu().tolist()\n",
    "            \n",
    "    # Calculate the metrics\n",
    "    accuracy = (num_correct / total) * 100.0\n",
    "    f1 = f1_score(labels_test, predictions_test, average='weighted')\n",
    "    mse = mean_squared_error(labels_test, predictions_test)\n",
    "    conf_matrix = confusion_matrix(labels_test, predictions_test, labels=[i for i in range(num_classes)])\n",
    "\n",
    "    return accuracy, f1, mse, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Best Parameters Using Grid Search\n",
    "\n",
    "No need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# classes = np.unique(train_labels)\n",
    "# num_classes = len(classes)\n",
    "# print(num_classes)\n",
    "\n",
    "# # Make a parameter grid for grid search\n",
    "# param_grid = {'epochs': [40, 50],\n",
    "#         'learning_rate': [0.01, 0.001, 0.0001],\n",
    "#         'momentum': [0.9, 0.95, 0.99, 0.999],\n",
    "#         'weight_decay': [0.01, 0.001],\n",
    "#         'decay_iter': [10000, 20000, 40000, 80000]\n",
    "#         }\n",
    "\n",
    "# # Store index of the best iteration for each metric\n",
    "# best_results = {'f1': 0, 'acc': 0, 'mse': 0}\n",
    "\n",
    "# # Store the f1 score, accuracy, MSEs, and confusion matrices for each parameter combination, as well as the parameters\n",
    "# metrics = {'f1_scores': [], 'accuracies': [], 'mses': [], 'conf_matrices': []}\n",
    "# results = {'train': [], 'test': [], 'params': [], 'best': best_results}\n",
    "\n",
    "# # Load data in batch sizes\n",
    "# train_loader = vd.build_dataloader(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = vd.build_dataloader(test_data, test_labels, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# best_acc = 0\n",
    "# best_f1 = 0\n",
    "# best_mse = float('inf')\n",
    "\n",
    "# # Apply grid search using the sklearn ParameterGrid\n",
    "# for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "#     print(f'iteration {i}: {params}')\n",
    "\n",
    "#     # Get the parameters\n",
    "#     learning_rate = params['learning_rate']\n",
    "#     momentum = params['momentum']\n",
    "#     weight_decay = params['weight_decay']\n",
    "#     decay_iter = params['decay_iter']\n",
    "#     epochs = params['epochs']\n",
    "\n",
    "#     # Store the metrics for this iteration so we can plot them later\n",
    "#     results['test'].append(metrics.copy())\n",
    "#     results['train'].append(metrics.copy())\n",
    "\n",
    "#     # Store the parameters for this iteration\n",
    "#     results['params'].append(params)\n",
    "\n",
    "#     # Initialize the model\n",
    "#     model = CNN.CNN(num_classes)\n",
    "#     model = model.float()\n",
    "#     model.to(dev)\n",
    "\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     batch_number = 0\n",
    "\n",
    "#     # Train and test the model for the specified number of epochs\n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         batch_number, learning_rate = train_cnn(model, optimizer, criterion, train_loader, batch_size, decay_iter, learning_rate, batch_number, dev)\n",
    "\n",
    "#         # Test cnn after training\n",
    "#         with torch.no_grad():\n",
    "            \n",
    "#             # Test the model on the training data\n",
    "#             accuracy, f1, mse, conf_matrix = test_cnn(model, batch_size, num_classes, train_loader)\n",
    "\n",
    "#             # Store the training results\n",
    "#             results['train'][i]['accuracies'].append(accuracy)\n",
    "#             results['train'][i]['f1_scores'].append(f1)\n",
    "#             results['train'][i]['mses'].append(mse)\n",
    "#             results['train'][i]['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "#             # Print final results of the model before moving on to the next parameter combination\n",
    "#             if epoch == epochs-1:\n",
    "#                 print(\"Final Training Accuracy:\", accuracy)\n",
    "#                 print(\"Final Training F1 Score:\", f1)\n",
    "#                 print(\"Final Training MSE:\", mse)\n",
    "\n",
    "#             # Test the model on the test data\n",
    "#             accuracy, f1, mse, conf_matrix = test_cnn(model, batch_size, num_classes, test_loader)\n",
    "\n",
    "#             # Store the results\n",
    "#             results['test'][i]['accuracies'].append(accuracy)\n",
    "#             results['test'][i]['f1_scores'].append(f1)\n",
    "#             results['test'][i]['mses'].append(mse)\n",
    "#             results['test'][i]['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "#             # Print final results of the model before moving on to the next parameter combination\n",
    "#             if epoch == epochs-1:\n",
    "#                 print(\"Final Testing Accuracy:\", accuracy)\n",
    "#                 print(\"Final Testing F1 Score:\", f1)\n",
    "#                 print(\"Final Testing MSE:\", mse)\n",
    "\n",
    "#             # Take note of the model with the best accuracy on the test set once all epochs are complete\n",
    "#             if accuracy > best_acc and epoch == epochs-1:\n",
    "#                 results['best']['acc'] = i\n",
    "            \n",
    "#             # Take note of the model with the best f1 score on the test set once all epochs are complete\n",
    "#             if f1 > best_f1 and epoch == epochs-1:\n",
    "#                 results['best']['f1'] = i\n",
    "\n",
    "#             # Take note of the model with the best MSE on the test set once all epochs are complete\n",
    "#             if mse < best_mse and epoch == epochs-1:\n",
    "#                 results['best']['mse'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "classes = np.unique(train_labels)\n",
    "num_classes = len(classes)\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "if training_set == \"Toys4k\":\n",
    "    epochs = 100\n",
    "\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 0.001\n",
    "decay_iter = 10000\n",
    "\n",
    "# Store the f1 score, accuracy, MSEs, and confusion matrices for each parameter combination, as well as the parameters\n",
    "train_results = {'f1_scores': [], 'accuracies': [], 'mses': [], 'conf_matrices': []}\n",
    "test_results = {'f1_scores': [], 'accuracies': [], 'mses': [], 'conf_matrices': []}\n",
    "\n",
    "# Load data in batch sizes\n",
    "train_loader = vd.build_dataloader(train_data, train_labels, batch_size=batch_size, shuffle=True)\n",
    "test_loader = vd.build_dataloader(test_data, test_labels, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN.CNN(num_classes)\n",
    "model = model.float()\n",
    "model.to(dev)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "batch_number = 0\n",
    "\n",
    "# Iterate through each epoch\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print (f\"Epoch: {epoch + 1}\")\n",
    "\n",
    "    # Train cnn\n",
    "    batch_number, learning_rate = train_cnn(model, optimizer, criterion, train_loader, batch_size, decay_iter, learning_rate, batch_number, dev)\n",
    "\n",
    "    # Test cnn after training\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Test the model on the training data\n",
    "        accuracy, f1, mse, conf_matrix = test_cnn(model, batch_size, num_classes, train_loader)\n",
    "\n",
    "        # Store the training results\n",
    "        train_results['accuracies'].append(accuracy)\n",
    "        train_results['f1_scores'].append(f1)\n",
    "        train_results['mses'].append(mse)\n",
    "        train_results['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "        print (f\"Training Accuracy: {accuracy}\")\n",
    "        print (f\"Training F1 Score: {f1}\")\n",
    "        print (f\"Training MSE: {mse}\")\n",
    "\n",
    "        # Test the model on the test data\n",
    "        accuracy, f1, mse, conf_matrix = test_cnn(model, batch_size, num_classes, test_loader)\n",
    "\n",
    "        # Store the results\n",
    "        test_results['accuracies'].append(accuracy)\n",
    "        test_results['f1_scores'].append(f1)\n",
    "        test_results['mses'].append(mse)\n",
    "        test_results['conf_matrices'].append(conf_matrix)\n",
    "\n",
    "        print (f\"\\nTesting Accuracy: {accuracy}\")\n",
    "        print (f\"Testing F1 Score: {f1}\")\n",
    "        print (f\"Testing MSE: {mse}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(f'{training_set} Accuracy')\n",
    "plt.plot(range(len(train_results['accuracies'])), train_results['accuracies'], label='Training Accuracy')\n",
    "plt.plot(range(len(test_results['accuracies'])), test_results['accuracies'], label='Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 Score\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(f'{training_set} F1 Score')\n",
    "plt.plot(range(len(train_results['f1_scores'])), train_results['f1_scores'], label='Training F1 Score')\n",
    "plt.plot(range(len(test_results['f1_scores'])), test_results['f1_scores'], label='Testing F1 Score')\n",
    "plt.legend()\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Plot MSE\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(f'{training_set} MSE')\n",
    "plt.plot(range(len(train_results['mses'])), train_results['mses'], label='Training MSE')\n",
    "plt.plot(range(len(test_results['mses'])), test_results['mses'], label='Testing MSE')\n",
    "plt.legend()\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()\n",
    "\n",
    "conf_matrix = test_results['conf_matrices'][-1]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "if training_set == \"Toys4k\":\n",
    "    plt.figure(figsize=(30, 30))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=classes)\n",
    "plt.title(f'{training_set} Confusion Matrix')\n",
    "disp.plot(ax=plt.subplot(111), xticks_rotation='vertical', cmap=plt.cm.Blues, include_values=True, values_format='d')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
